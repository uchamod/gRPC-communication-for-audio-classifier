# ğŸ™ï¸ Flutter + Flask gRPC Audio Classification App

A **Flutter client** that communicates with a **Flask-based AI server** over **gRPC** to classify environmental sounds (like barking, sirens, etc.) using the **YAMNet** model from TensorFlow Hub.

---

## ğŸ§  Overview

This project demonstrates how to integrate **Flutter** (Dart) with a **Python Flask + TensorFlow** backend using **gRPC** instead of traditional REST APIs â€” enabling faster, more efficient binary data transmission for tasks like audio classification.

---

## âš™ï¸ Architecture

```
ğŸ™ï¸ Flutter App (Client)
   â†“ gRPC (Protocol Buffers)
ğŸ§  Flask + YAMNet (Python Server)
   â†“
TensorFlow Hub Model (YAMNet)
```

* The Flutter app records or selects an audio file.
* The audio bytes are sent to the Flask AI server via **gRPC**.
* The Flask server runs **YAMNet** to classify the sound.
* The predicted label and confidence score are returned to the Flutter app.

---

## ğŸš€ Features

âœ… Real-time audio classification (YAMNet model)
âœ… gRPC-based communication (efficient + type-safe)
âœ… File selection and playback in Flutter
âœ… Modular, production-ready structure
âœ… Easily extendable for other AI models (image, text, etc.)

---

## ğŸ§© Tech Stack

### Frontend (Flutter)

* Flutter SDK â‰¥ 3.0
* Dart â‰¥ 3.0
* Packages:

  * `grpc` â€” gRPC client communication
  * `file_picker` â€” select local audio files
  * `just_audio` â€” audio playback (optional)
  * `riverpod` â€” state management (optional)

### Backend (Python)

* Flask (for optional REST interface)
* `grpcio` and `grpcio-tools` â€” gRPC server implementation
* `tensorflow` and `tensorflow_hub` â€” AI inference (YAMNet model)
* `numpy` â€” data processing

---

## ğŸ“ Project Structure

### Flutter (client)

```
lib/
â”œâ”€â”€ generated/
â”‚   â”œâ”€â”€ audio_service.pb.dart
â”‚   â”œâ”€â”€ audio_service.pbgrpc.dart
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ grpc/
â”‚   â”‚   â””â”€â”€ audio_grpc_client.dart       # Handles gRPC calls
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ audio_result.dart            # Result model
â”‚
â”œâ”€â”€ screens/
â”‚   â”œâ”€â”€ home_screen.dart                 # UI for file selection & result
â”‚
â”œâ”€â”€ providers/
â”‚   â””â”€â”€ audio_provider.dart              # (Optional) Riverpod logic
â”‚
â””â”€â”€ main.dart                            # App entry point
```

### Flask (server)

```
server/
â”œâ”€â”€ audio_service.proto                  # gRPC definition
â”œâ”€â”€ audio_service_pb2.py
â”œâ”€â”€ audio_service_pb2_grpc.py
â”œâ”€â”€ grpc_server.py                       # Flask + gRPC setup
â””â”€â”€ yamnet_model.py                      # YAMNet inference logic
```

---

## ğŸ“œ Proto Definition (`audio_service.proto`)

```proto
syntax = "proto3";

service AudioClassifier {
  rpc Predict (AudioRequest) returns (AudioResponse);
}

message AudioRequest {
  bytes audio_data = 1;
}

message AudioResponse {
  string label = 1;
  float confidence = 2;
}
```

---

## ğŸ”§ Setup & Installation

### 1ï¸âƒ£ Clone the repo

```bash
git clone https://github.com/yourusername/flutter-flask-grpc-audio.git
cd flutter-flask-grpc-audio
```

---

### 2ï¸âƒ£ Backend Setup (Flask + gRPC)

#### Install dependencies

```bash
cd server
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

#### Generate Python gRPC files

```bash
python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. audio_service.proto
```

#### Run the gRPC server

```bash
python grpc_server.py
```

Server starts on port `50051`.

---

### 3ï¸âƒ£ Flutter Client Setup

#### Install dependencies

```bash
cd flutter_client
flutter pub get
```

#### Generate Dart gRPC files

```bash
protoc --dart_out=grpc:lib/generated audio_service.proto
```

#### Run app

```bash
flutter run
```

---

## ğŸ§  How It Works

| Step | Description                                                     |
| ---- | --------------------------------------------------------------- |
| 1ï¸âƒ£  | User selects or records an audio file in the Flutter app        |
| 2ï¸âƒ£  | Flutter reads the file bytes and sends via gRPC to Flask server |
| 3ï¸âƒ£  | Flask server processes it using YAMNet model                    |
| 4ï¸âƒ£  | Model outputs a label and confidence                            |
| 5ï¸âƒ£  | Flask sends the result back to Flutter                          |
| 6ï¸âƒ£  | Flutter displays the prediction on screen                       |

---

---

## ğŸ”’ Security Notes

* For development, the gRPC connection uses **insecure credentials**.
* In production, use **TLS encryption** with `ChannelCredentials.secure()` in Flutter and `ServerCredentials.createSsl()` in Flask.

---

## ğŸ§© Future Improvements

* ğŸ” Implement **streaming gRPC** for continuous audio inference
* âš¡ Add **auth tokens** for secure access
* â˜ï¸ Deploy the Flask gRPC server on **Google Cloud Run / AWS EC2**
* ğŸ“Š Add history and charts of detected sounds
* ğŸ¯ Use **Firebase** for push notifications on danger sounds

---

## ğŸ§‘â€ğŸ’» Author

**Chamod Udara**
ğŸ“± Flutter Developer | ğŸ”— Backend Integrator
ğŸ’¡ Passionate about AI + Mobile synergy

---


